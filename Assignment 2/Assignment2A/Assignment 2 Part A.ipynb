{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Reshape, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed, no need change\n",
    "def load_data(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        try:\n",
    "            samples = pickle.load(fo)\n",
    "        except UnicodeDecodeError:  # python 3.x\n",
    "            fo.seek(0)\n",
    "            samples = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "    data, labels = samples['data'], samples['labels']\n",
    "\n",
    "    data = np.array(data, dtype=np.float32) / 255\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(num_ch_c1, num_ch_c2, use_dropout):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Conv2D(num_ch_c1, kernel_size=9,  padding='valid', activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"valid\"))\n",
    "    model.add(Conv2D(num_ch_c2, kernel_size=5, padding='valid', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding=\"valid\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(300))\n",
    "    \n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(question, optimizer_, num_ch_c1, num_ch_c2, use_dropout):\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    result_dir = \"./results\"\n",
    "    model_dir = \"./models\"\n",
    "    \n",
    "    epochs = 1000  # Fixed\n",
    "    batch_size = 128  # Fixed\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    model = make_model(num_ch_c1, num_ch_c2, use_dropout)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    if optimizer_ == 'SGD':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_ == 'SGD-momentum':  # Question 3(a)\n",
    "        optimizer = SGD(learning_rate=learning_rate, momentum = 0.1)\n",
    "    elif optimizer_ == 'RMSprop':  # Question 3(b)\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_ == 'Adam':  # Question 3(c)\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError(f'You do not need to handle [{optimizer_}] in this project.')\n",
    "\n",
    "    # Training and test\n",
    "    x_train, y_train = load_data('data_batch_1')\n",
    "    x_test, y_test = load_data('test_batch_trim')\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    train_x, test_x = [], []\n",
    "    for img in x_test:\n",
    "        test_x.append(np.transpose(np.reshape(img,(3, 32,32)), (1,2,0)))\n",
    "    for img in x_train:\n",
    "        train_x.append(np.transpose(np.reshape(img,(3, 32,32)), (1,2,0)))\n",
    "    x_train=np.array(train_x)\n",
    "    x_test=np.array(test_x)\n",
    "\n",
    "    # Training\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test))\n",
    "\n",
    "    ''' Fill in Question 1(b) here. This website may help:\n",
    "            https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0\n",
    "    '''\n",
    "\n",
    "    # Create folder to store models and results\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "\n",
    "    # Save model\n",
    "    if use_dropout:\n",
    "        model.save(f'{model_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout')\n",
    "    else:\n",
    "        model.save(f'{model_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout')\n",
    "\n",
    "    # Save the plot for losses\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    test_acc = history.history['val_accuracy']\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Test')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'{result_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_loss.png')\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'{result_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_loss.png'\n",
    "        )\n",
    "    plt.close()\n",
    "\n",
    "    # Save the plot for accuracies\n",
    "    plt.plot(range(1, len(train_acc) + 1), train_acc, label='Train')\n",
    "    plt.plot(range(1, len(test_acc) + 1), test_acc, label='Test')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'{result_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_accuracy.png'\n",
    "        )\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'{result_dir}/q{question}_{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_accuracy.png'\n",
    "        )\n",
    "    plt.close()\n",
    "    \n",
    "    return model, history.history['val_accuracy'], history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 1B\n",
    "def get_features(model):\n",
    "    fig_dir = \"./figure\"\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.mkdir(fig_dir)\n",
    "    \n",
    "    #Get first 2 test image\n",
    "    x_test, _ = load_data('test_batch_trim')\n",
    "    test_x = []\n",
    "    for img in x_test:\n",
    "        test_x.append(np.transpose(np.reshape(img,(3, 32,32)), (1,2,0)))\n",
    "    test_x=np.array(test_x)\n",
    "    test = test_x[:2]\n",
    "\n",
    "    #Create model to take input and output conv1, pool1, conv2, pool2\n",
    "    layer_output = [layer.output for layer in model.layers[0:4]]\n",
    "\n",
    "    layer_name = []\n",
    "    print(f\"layer_output consist of:\")\n",
    "    for i in layer_output:\n",
    "        layer_name.append(str(i).split('\"')[1].split('/')[0])\n",
    "        print(i)\n",
    "\n",
    "    #Create model for feature map output\n",
    "    activate_model = models.Model(model.input,layer_output)\n",
    "\n",
    "    #Predict first 2 test value\n",
    "    feature_map = activate_model.predict(test)\n",
    "\n",
    "    #Feature Map shapes\n",
    "    for layer in feature_map:\n",
    "        print(layer.shape)\n",
    "    \n",
    "    #Save Test Image and Features Map\n",
    "    imgcnt = 1\n",
    "    for img in test:\n",
    "        plt.figure()\n",
    "        plt.title(f\"Test Image {imgcnt}\")\n",
    "        plt.gray()\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img)\n",
    "        plt.savefig(f\"{fig_dir}/1b_TestImage{imgcnt}.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        featurecnt = 0\n",
    "        for layer in feature_map:\n",
    "            plt.figure()\n",
    "            plt.title(f\"Feature Map of {layer_name[featurecnt]}\") #NOT SURE WHY NOT PRINTING!\n",
    "            \n",
    "            channel = layer.shape[-1]\n",
    "            for j in range(channel):\n",
    "                plt.subplot(10, int(channel/10), j+1)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(layer[imgcnt-1,:,:,j], cmap='viridis')\n",
    "            plt.savefig(f\"{fig_dir}/1b_TestImage{imgcnt}_{layer_name[featurecnt]}.png\")\n",
    "            plt.close()\n",
    "            featurecnt+=1\n",
    "        imgcnt+=1\n",
    "    print(f\"Features Map Generated. Image saved at ./figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 5/79 [>.............................] - ETA: 6s - loss: 2.3036 - accuracy: 0.0875"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-378b04a10ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"SGD\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_dropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0macc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"q\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m#Question 1B\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-e4701134b3fb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(question, optimizer_, num_ch_c1, num_ch_c2, use_dropout)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     ''' Fill in Question 1(b) here. This website may help:\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    grid_dir = \"./grid_results\"\n",
    "    if not os.path.exists(grid_dir):\n",
    "        os.mkdir(grid_dir)\n",
    "    \n",
    "    #Fill in the list with question you want to do. Question 3 have to complete Question 2\n",
    "    #Other values is for testing models\n",
    "    question = [1,2,3]\n",
    "    acc = {}\n",
    "    \n",
    "    for i in question:\n",
    "        if i == 1:\n",
    "            c1 = 50\n",
    "            c2 = 60\n",
    "            opt = \"SGD\"\n",
    "            model, data, val_acc = main(i, opt, c1, c2, use_dropout=False)\n",
    "            acc[\"q\"+str(i)+\"_\"+str(c1)+\"_\"+str(c2)] = val_acc\n",
    "            \n",
    "            #Question 1B\n",
    "            get_features(model)\n",
    "                \n",
    "        elif i == 2:\n",
    "            #Grid Search for c1 and c2\n",
    "            Q2_c1 = [10,30,50,70,90]\n",
    "            Q2_c2 = [20,40,60,80,100]\n",
    "            opt = \"SGD\"\n",
    "\n",
    "            #Question 2\n",
    "            for c1 in Q2_c1:\n",
    "                datalist=[]\n",
    "                for c2 in Q2_c2:\n",
    "                    _, data, val_acc = main(i, opt, c1, c2, use_dropout=False)\n",
    "                    acc[\"q\"+str(i)+\"_\"+str(c1)+\"_\"+str(c2)] = val_acc\n",
    "                    datalist.append(data)\n",
    "                    \n",
    "                #Plot validation accuracy and save\n",
    "                plt.title(f'Model Validation Accuracy for {opt}_C1={c1}')\n",
    "                plt.ylabel('Val_Accuracy')\n",
    "                plt.xlabel('epochs')\n",
    "                for j in range(len(datalist)):\n",
    "                    plt.plot(datalist[j], label=f'{opt}_{c1}_{Q2_c2[j]}')\n",
    "                plt.legend(loc=\"best\")\n",
    "                plt.savefig(f\"{grid_dir}/q{i}_{opt}_{c1}.png\")\n",
    "                plt.close()\n",
    "            \n",
    "        elif i == 3:\n",
    "            #Obtain optimal combination channel for c1 and c2\n",
    "            value =  {k:v for k, v in acc.items() if k.split(\"_\")[0] == \"q2\"}\n",
    "            c1 = int(max(value, key=value.get).split(\"_\")[1])\n",
    "            c2 = int(max(value, key=value.get).split(\"_\")[2])\n",
    "\n",
    "            #Declare type of optimizer\n",
    "            optimizers = [\"SGD\", \"SGD-momentum\", \"RMSprop\", \"Adam\"]\n",
    "            datalist=[]\n",
    "            \n",
    "            #Question 3A, 3B, 3C, 3D\n",
    "            for optimizer in optimizers:\n",
    "                _, data, val_acc = main(i, optimizer, c1, c2, use_dropout=False)\n",
    "                acc[\"q\"+str(i)+\"_\"+str(c1)+\"_\"+str(c2)] = val_acc\n",
    "                datalist.append(data)\n",
    "                \n",
    "            _, data, val_acc = main(i, \"SGD\", c1, c2, use_dropout=True)\n",
    "            acc[\"q\"+str(i)+\"_\"+str(c1)+\"_\"+str(c2)] = val_acc\n",
    "            datalist.append(data)\n",
    "            optimizers.append(\"SGD_w_dropout\")\n",
    "            \n",
    "            #Plot validation accuracy and save\n",
    "            plt.title(f'Model Validation Accuracy for Models')\n",
    "            plt.ylabel('Val_Accuracy')\n",
    "            plt.xlabel('epochs')\n",
    "            for k in range(len(datalist)):\n",
    "                plt.plot(datalist[k], label=f'{optimizers[k]}_{c1}_{c2}')\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.savefig(f\"q{i}_Models_{c1}_{c2}.png\")\n",
    "            plt.close()\n",
    "            \n",
    "        else:\n",
    "            #Test model\n",
    "            c1=70\n",
    "            c2=80\n",
    "            model, data, val_acc = main(i, \"Adam\", c1, c2, use_dropout=True)\n",
    "            acc[\"q\"+str(i)+\"_\"+str(c1)+\"_\"+str(c2)] = val_acc\n",
    "    \n",
    "    #Export val_accuracy to excel for comparison\n",
    "    acc_models3 = pd.Series(acc, name='Val_Accuracy')\n",
    "    acc_models3.to_excel(\"Models_Accuracy.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
